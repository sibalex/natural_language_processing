{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "izA3-6kffbdT"
   },
   "source": [
    "# Используем BERT впервые\n",
    "\n",
    "Источник: [Jay Alamar](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)\n",
    "\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-sentence-classification.png\" />\n",
    "\n",
    "In this notebook, we will use pre-trained deep learning model to process some text. We will then use the output of that model to classify the text. The text is a list of sentences from film reviews. And we will calssify each sentence as either speaking \"positively\" about its subject of \"negatively\".\n",
    "\n",
    "## Models: Sentence Sentiment Classification\n",
    "Our goal is to create a model that takes a sentence (just like the ones in our dataset) and produces either 1 (indicating the sentence carries a positive sentiment) or a 0 (indicating the sentence carries a negative sentiment). We can think of it as looking like this:\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/sentiment-classifier-1.png\" />\n",
    "\n",
    "Under the hood, the model is actually made up of two model.\n",
    "\n",
    "* DistilBERT processes the sentence and passes along some information it extracted from it on to the next model. DistilBERT is a smaller version of BERT developed and open sourced by the team at HuggingFace. It’s a lighter and faster version of BERT that roughly matches its performance.\n",
    "* The next model, a basic Logistic Regression model from scikit learn will take in the result of DistilBERT’s processing, and classify the sentence as either positive or negative (1 or 0, respectively).\n",
    "\n",
    "The data we pass between the two models is a vector of size 768. We can think of this of vector as an embedding for the sentence that we can use for classification.\n",
    "\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/distilbert-bert-sentiment-classifier.png\" />\n",
    "\n",
    "## Dataset\n",
    "The dataset we will use in this example is [SST2](https://nlp.stanford.edu/sentiment/index.html), which contains sentences from movie reviews, each labeled as either positive (has the value 1) or negative (has the value 0):\n",
    "\n",
    "\n",
    "<table class=\"features-table\">\n",
    "  <tr>\n",
    "    <th class=\"mdc-text-light-green-600\">\n",
    "    sentence\n",
    "    </th>\n",
    "    <th class=\"mdc-text-purple-600\">\n",
    "    label\n",
    "    </th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror films\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      apparently reassembled from the cutting room floor of any given daytime soap\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      they presume their audience won't sit still for a sociology lesson\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      0\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      this is a visually stunning rumination on love , memory , history and the war between art and commerce\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"mdc-bg-light-green-50\" style=\"text-align:left\">\n",
    "      jonathan parker 's bartleby should have been the be all end all of the modern office anomie films\n",
    "    </td>\n",
    "    <td class=\"mdc-bg-purple-50\">\n",
    "      1\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the transformers library\n",
    "Let's start by installing the huggingface transformers library so we can load our deep learning NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:50:37.539693Z",
     "start_time": "2019-12-29T12:50:28.870813Z"
    },
    "cell_style": "split",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "colab_type": "code",
    "id": "To9ENLU90WGl",
    "outputId": "a2c5b6ad-e0da-49f9-9817-568d63b6861d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/10/aeefced99c8a59d828a92cc11d213e2743212d3641c87c82d61b035a7d5c/transformers-2.3.0-py3-none-any.whl (447kB)\n",
      "\u001b[K     |████████████████████████████████| 450kB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/56/2e6cfc364c4760b85adab40cb38d91e7ce67d6b2745a2e1aa1497c776fe1/sentencepiece-0.1.85-cp37-cp37m-macosx_10_6_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from transformers) (4.32.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from transformers) (2019.12.9)\n",
      "Requirement already satisfied: boto3 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from transformers) (1.10.39)\n",
      "Requirement already satisfied: numpy in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from transformers) (1.16.4)\n",
      "Requirement already satisfied: requests in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Collecting sacremoses (from transformers)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
      "\u001b[K     |████████████████████████████████| 860kB 1.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.39 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from boto3->transformers) (1.13.39)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from requests->transformers) (2019.6.16)\n",
      "Requirement already satisfied: six in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.39->boto3->transformers) (0.14)\n",
      "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from botocore<1.14.0,>=1.13.39->boto3->transformers) (2.8.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/aleksandr/Library/Caches/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.3.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:56:23.109487Z",
     "start_time": "2019-12-29T12:55:58.443204Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/71/0e76ba50c8c9aeb8349d827d02278c1b5eb4da9cdc17ca26b5bd47ec034a/torchvision-0.4.2-cp37-cp37m-macosx_10_7_x86_64.whl (641kB)\n",
      "\u001b[K     |████████████████████████████████| 645kB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from torchvision) (6.1.0)\n",
      "Collecting torch==1.3.1 (from torchvision)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/94/0ed9f7899aa0f5e7ff753a3a2b6944c146eef3f4cd51c59ab07c4575992b/torch-1.3.1-cp37-none-macosx_10_7_x86_64.whl (71.1MB)\n",
      "\u001b[K     |████████████████████████████████| 71.1MB 453kB/s eta 0:00:01     |█████▋                          | 12.5MB 4.3MB/s eta 0:00:14     |█████████████████████████████   | 64.6MB 3.8MB/s eta 0:00:02\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/aleksandr/anaconda3/lib/python3.7/site-packages (from torchvision) (1.16.4)\n",
      "Installing collected packages: torch, torchvision\n",
      "Successfully installed torch-1.3.1 torchvision-0.4.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:08:46.453632Z",
     "start_time": "2019-12-29T14:08:46.448992Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "colab_type": "code",
    "id": "fvFvBLJV0Dkv",
    "outputId": "f96095a0-78c8-463a-fcae-3cddcce7fae7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import torch\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zQ-42fh0hjsF"
   },
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:57:35.110470Z",
     "start_time": "2019-12-29T12:57:33.610328Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "cyoj29J24hPX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:57:36.250788Z",
     "start_time": "2019-12-29T12:57:36.217368Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "colab_type": "code",
    "id": "_8hu_H0-xnrd",
    "outputId": "6f53cd0a-8b79-4d9e-ee31-0ce1da12c10f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "colab_type": "text",
    "id": "dMVE3waNhuNj"
   },
   "source": [
    "Возьмём первые 2,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:57:40.000289Z",
     "start_time": "2019-12-29T12:57:39.996510Z"
    },
    "cell_style": "center",
    "colab": {},
    "colab_type": "code",
    "id": "gTM3hOHW4hUY"
   },
   "outputs": [],
   "source": [
    "batch_1 = df[:2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRc2L89hh1Tf"
   },
   "source": [
    "Баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T12:57:42.909859Z",
     "start_time": "2019-12-29T12:57:42.888140Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "jGvcfcCP5xpZ",
    "outputId": "594d89c6-70f4-4497-ee2e-e3f34f00e76c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1041\n",
       "0     959\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_MO08_KiAOb"
   },
   "source": [
    "## Loading the Pre-trained BERT model\n",
    "Let's now load a pre-trained BERT model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:08:11.156139Z",
     "start_time": "2019-12-29T14:05:34.102340Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "q1InADgf5xm2"
   },
   "outputs": [],
   "source": [
    "# For DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "## Want BERT instead of distilBERT? Uncomment the following line:\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:10:55.248627Z",
     "start_time": "2019-12-29T14:10:47.951877Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = ppb.DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = ppb.DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lZDBMn3wiSX6"
   },
   "source": [
    "Right now, the variable `model` holds a pretrained distilBERT model -- a version of BERT that is smaller, but much faster and requiring a lot less memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация\n",
    "Our first step is to tokenize the sentences -- break them up into word and subwords in the format BERT is comfortable with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1 = batch_1[0].iloc[0]\n",
    "# display(text1)\n",
    "\n",
    "# text1_tokenised = tokenizer.encode(text1, add_special_tokens=True)\n",
    "# for word_id in text1_tokenised:\n",
    "#     print(tokenizer.ids_to_tokens[word_id])\n",
    "\n",
    "\n",
    "# tokenizer.vocab['film']\n",
    "# tokenizer.ids_to_tokens[2143]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:05.451362Z",
     "start_time": "2019-12-29T14:11:04.627995Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "Dg82ndBA5xlN"
   },
   "outputs": [],
   "source": [
    "tokenized = batch_1[0].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mHwjUwYgi-uL"
   },
   "source": [
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-distilbert-tokenization-2-token-ids.png\" />\n",
    "\n",
    "### Padding\n",
    "Выравниваем предложения по длине с помощью нулевых токенов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:25.373727Z",
     "start_time": "2019-12-29T14:11:25.336590Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "URn-DWJt5xhP"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:26.836297Z",
     "start_time": "2019-12-29T14:11:26.828229Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jdi7uXo95xeq",
    "outputId": "44b97142-0f08-4fd1-fc4a-a3b2d56b7f41"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDZBsYSDjzDV"
   },
   "source": [
    "### Masking\n",
    "\n",
    "Теперь создаём отдельную переменную, чтобы сказать берту, что надо игнорировать паддинг при подсчёте attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:29.511138Z",
     "start_time": "2019-12-29T14:11:29.504350Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4K_iGRNa_Ozc",
    "outputId": "2726cb95-1e08-4a68-e189-fce2ca4f974d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:31.655125Z",
     "start_time": "2019-12-29T14:11:31.648337Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "BufTWLdDqR7F",
    "outputId": "76a515d6-fd71-4952-bba3-99050f4a41b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:11:36.994510Z",
     "start_time": "2019-12-29T14:11:36.986300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jK-CQB9-kN99"
   },
   "source": [
    "## Используем BERT\n",
    "\n",
    "Функция `model()` прогоняет предложения через BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:16:39.044964Z",
     "start_time": "2019-12-29T14:12:31.149329Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "39UVjAV56PJz"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:16:39.123674Z",
     "start_time": "2019-12-29T14:16:39.082262Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000, 59, 768])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FoCep_WVuB3v"
   },
   "source": [
    "Let's slice only the part of the output that we need. That is the output corresponding the first token of each sentence. The way BERT does sentence classification, is that it adds a token called `[CLS]` (for classification) at the beginning of every sentence. The output corresponding to that token can be thought of as an embedding for the entire sentence.\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/distilBERT/bert-output-tensor-selection.png\" />\n",
    "\n",
    "Берём оттуда только представления первого токена -- `[CLS]`. Это представление и будет нашими признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:16:39.169893Z",
     "start_time": "2019-12-29T14:16:39.130766Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "C9t60At16PVs"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:16:39.183566Z",
     "start_time": "2019-12-29T14:16:39.173473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_VZVU66Gurr-"
   },
   "source": [
    "Метки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:16:39.204841Z",
     "start_time": "2019-12-29T14:16:39.195129Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JD3fX2yh6PTx"
   },
   "outputs": [],
   "source": [
    "labels = batch_1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:22.908494Z",
     "start_time": "2019-12-29T14:18:22.900843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "5    1\n",
       "6    0\n",
       "7    1\n",
       "8    0\n",
       "9    0\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iaoEvM2evRx1"
   },
   "source": [
    "## LogReg на фичах из BERT\n",
    "Let's now split our datset into a training set and testing set (even though we're using 2,000 sentences from the SST2 training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:30.096986Z",
     "start_time": "2019-12-29T14:18:30.020501Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ddAqbkoU6PP9"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KCT9u8vAwnID"
   },
   "source": [
    "We now train the LogisticRegression model. If you've chosen to do the gridsearch, you can plug the value of C into the model declaration (e.g. `LogisticRegression(C=5.2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:33.642326Z",
     "start_time": "2019-12-29T14:18:33.261287Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "gG-EVWx4CzBc",
    "outputId": "61bb0415-7fe6-4979-ff01-5f7109fce541"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rUMKuVgwzkY"
   },
   "source": [
    "## Оцениваем результат\n",
    "Accuracy на тесте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:36.483823Z",
     "start_time": "2019-12-29T14:18:36.346353Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "iCoyxRJ7ECTA",
    "outputId": "01c1648d-7516-49b2-a36f-899485e38a1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_clf.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:55.444129Z",
     "start_time": "2019-12-29T14:18:55.441173Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:18:57.317432Z",
     "start_time": "2019-12-29T14:18:57.307056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       248\n",
      "           1       0.85      0.81      0.83       252\n",
      "\n",
      "    accuracy                           0.83       500\n",
      "   macro avg       0.83      0.83      0.83       500\n",
      "weighted avg       0.83      0.83      0.83       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = lr_clf.predict(test_features)\n",
    "print(classification_report(test_labels, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "75oyhr3VxHoE"
   },
   "source": [
    "Сравним с DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-29T14:19:05.816307Z",
     "start_time": "2019-12-29T14:19:05.794425Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lnwgmqNG7i5l",
    "outputId": "4ec20186-e6ef-4b9d-a704-2b108051b25b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy classifier score: 0.495 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "# классификатор который рандомно выставляет метки при этом учитывая распределение классов\n",
    "# используют для сравнения со случайным ответом\n",
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier()\n",
    "\n",
    "scores = cross_val_score(clf, train_features, train_labels)\n",
    "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# поскольку у нас сбалансированный ds с бинарной классификацией выдает в районе 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Lg4LOpoxSOR"
   },
   "source": [
    "А что насчёт луших классификаторов?\n",
    "\n",
    "## Proper SST2 scores\n",
    "For reference, the [highest accuracy score](http://nlpprogress.com/english/sentiment_analysis.html) for this dataset is currently **96.8**. DistilBERT can be trained to improve its score on this task – a process called **fine-tuning** which updates BERT’s weights to make it achieve a better performance in this sentence classification task (which we can call the downstream task). The fine-tuned DistilBERT turns out to achieve an accuracy score of **90.7**. The full size BERT model achieves **94.9**.\n",
    "\n",
    "\n",
    "\n",
    "And that’s it! That’s a good first contact with BERT. The next step would be to head over to the documentation and try your hand at [fine-tuning](https://huggingface.co/transformers/examples.html#glue). You can also go back and switch from distilBERT to BERT and see how that works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "name": "BERT_First_Time.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
