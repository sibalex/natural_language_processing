{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing \n",
    "\n",
    "https://github.com/maryszmary/nlp-netology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные задачи\n",
    "\n",
    "### Классификация текстов\n",
    "   * Фильтрация спама\n",
    "   * Анализ тональности\n",
    "   * Определение интента\n",
    "   * По теме или жанру\n",
    "   \n",
    "### Кластеризация текстов\n",
    "   * Аггрегация новостей\n",
    "   * Рекомендации\n",
    "   \n",
    "### Извлечение информации\n",
    "   * Именованные сущности (NER), отношения\n",
    "   * Факты и события   \n",
    "\n",
    "### Другие приложения\n",
    "   * Машинный перевод\n",
    "   * Вопросно-ответные системы\n",
    "   * Саммаризация текстов\n",
    "   * Генерация текста\n",
    "   * Распознавание речи\n",
    "   * Проверка правописания (spell-checking)\n",
    "   * Распознавание символов (OCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "![pipeline.png](nlp_pipeline.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Обработка текста\n",
    "\n",
    "#### Уровень символов:\n",
    "   * Токенизация: разбиение текста на слова\n",
    "   * Разбиение текста на предложения\n",
    "   \n",
    "#### Уровень слов (морфология):\n",
    "   * Определение частей речи (POS-tagging)\n",
    "   * Снятие морфологической неоднозначности\n",
    "   \n",
    "#### Уровень предложений (синтаксис):\n",
    "   * Выделенние именных или глагольных групп (chunking)\n",
    "   * Выделенние семантических ролей\n",
    "   * Деревья составляющих и зависимостей\n",
    "   \n",
    "#### Уровень смысла (семантика и дискурс):\n",
    "   * Разрешение кореферентных связей\n",
    "   * Выделение синонимов\n",
    "   * Анализ аргументативных связей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Основные проблемы\n",
    "\n",
    "* Неоднозначность\n",
    "    * Лексическая неоднозначность: *орган, парить, рожки, атлас*\n",
    "    * Морфологическая неоднозначность: *Хранение денег в банке. Что делают белки в клетке?*\n",
    "    * Синтаксическая неоднозначность: *Его удивил простой солдат.*\n",
    "* Неологизмы: *печеньки, заинстаграммить, репостнуть, расшарить, затащить, килорубли*\n",
    "* Разные варианты написания: *Россия, Российская Федерация, РФ*\n",
    "* Нестандартное написание: *каг дила?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Синтаксическая неоднозначность\n",
    "\n",
    "### I saw a man on the hill with a telescope\n",
    "\n",
    "![syntax_ambiguaty](syntax_ambg.jpg)\n",
    "\n",
    "    I saw the man. The man was on the hill. I was using a telescope.\n",
    "    I saw the man. I was on the hill. I was using a telescope.\n",
    "    I saw the man. The man was on the hill. The hill had a telescope.\n",
    "    I saw the man. I was on the hill. The hill had a telescope.\n",
    "    I saw the man. The man was on the hill. I saw him using a telescope."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# План курса\n",
    "\n",
    "1. Предварительная обработка текстов\n",
    "2. Извлечение ключевых слов и синтаксический анализ \n",
    "3. Векторная модель, тематическое моделирование\n",
    "4. Векторная модель, дистрибутивная семантика\n",
    "5. Классификация текстов\n",
    "6. Языковые модели \n",
    "7. Извлечение информации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предварительная обработка текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Классификацию по тональности используют в рекомендательных системах, чтобы понять, понравилось ли людям кафе, кино, etc.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-10-21 00:23:23--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2019-10-21 00:23:24--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com/cd/0/inline/Aq0h6U4RZXXe-_DGwC5hsc6lGVhdiuKHewci29tLupXVBLB_LraDyM85eX2CPQppp2Otr99D6tL7GmBt_eU1gWlrjSVP2L-vVjFsMAugcz6quA/file# [following]\n",
      "--2019-10-21 00:23:24--  https://uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com/cd/0/inline/Aq0h6U4RZXXe-_DGwC5hsc6lGVhdiuKHewci29tLupXVBLB_LraDyM85eX2CPQppp2Otr99D6tL7GmBt_eU1gWlrjSVP2L-vVjFsMAugcz6quA/file\n",
      "Resolving uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com (uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com (uc1054232706506e95fbe4c478f4.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv’\n",
      "\n",
      "positive.csv        100%[===================>]  25,02M  3,58MB/s    in 6,9s    \n",
      "\n",
      "2019-10-21 00:23:31 (3,64 MB/s) - ‘positive.csv’ saved [26233379/26233379]\n",
      "\n",
      "--2019-10-21 00:23:32--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.70.1, 2620:100:6026:1::a27d:4601\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.70.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2019-10-21 00:23:32--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com/cd/0/inline/Aq39sDoDyWT--0p0NBVkRxrzI8k51nEiv9orx4YFcQargiwMd3yZkePgBovAd0RwqlfkIHD_Ct7gFPMCJV5g__Rz99hQuxrVFIcb4FW9285oEA/file# [following]\n",
      "--2019-10-21 00:23:32--  https://ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com/cd/0/inline/Aq39sDoDyWT--0p0NBVkRxrzI8k51nEiv9orx4YFcQargiwMd3yZkePgBovAd0RwqlfkIHD_Ct7gFPMCJV5g__Rz99hQuxrVFIcb4FW9285oEA/file\n",
      "Resolving ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com (ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com)... 162.125.70.6, 2620:100:6026:6::a27d:4606\n",
      "Connecting to ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com (ucefdf54b0e3f943769aebc543f8.dl.dropboxusercontent.com)|162.125.70.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv’\n",
      "\n",
      "negative.csv        100%[===================>]  23,32M  3,81MB/s    in 6,1s    \n",
      "\n",
      "2019-10-21 00:23:39 (3,84 MB/s) - ‘negative.csv’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "df = positive.append(negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226834, 2)\n",
      "(170125,)\n",
      "(56709,)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@first_timee хоть я и школота, но поверь, у нас то же самое :D общество профилирующий предмет типа)',\n",
       " 'Да, все-таки он немного похож на него. Но мой мальчик все равно лучше:D',\n",
       " 'RT @KatiaCheh: Ну ты идиотка) я испугалась за тебя!!!',\n",
       " 'RT @digger2912: \"Кто то в углу сидит и погибает от голода, а мы ещё 2 порции взяли, хотя уже и так жрать не хотим\" :DD http://t.co/GqG6iuE2…',\n",
       " '@irina_dyshkant Вот что значит страшилка :D\\nНо блин,посмотрев все части,у тебя создастся ощущение,что авторы курили что-то :D']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].head().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ngram_range` отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "* ngram_range=(1, 1) -- униграммы<br/>\n",
    "* ngram_range=(3, 3) -- триграммы<br/>\n",
    "* ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В `vec.vocabulary_` лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('это', 241541),\n",
       " ('удивительно', 226159),\n",
       " ('никогда', 168166),\n",
       " ('не', 165376),\n",
       " ('думала', 128880),\n",
       " ('что', 237532),\n",
       " ('скажу', 209677),\n",
       " ('так', 219528),\n",
       " ('но', 168564),\n",
       " ('хочу', 234262),\n",
       " ('себе', 207876),\n",
       " ('щенка', 240028),\n",
       " ('песни', 181552),\n",
       " ('братьев', 108026),\n",
       " ('самойловых', 206114),\n",
       " ('наверное', 161991),\n",
       " ('самое', 206108),\n",
       " ('приятное', 195039),\n",
       " ('воспоминание', 114658),\n",
       " ('из', 139352)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне'),\n",
       " ('б', 'мне', 'платили'),\n",
       " ('мне', 'платили', 'каждый'),\n",
       " ('платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 3)) # триграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.76      0.76     28133\n",
      "    positive       0.76      0.77      0.77     28576\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.57     18256\n",
      "    positive       0.82      0.61      0.70     38453\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.64      0.67      0.63     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26694\n",
      "    positive       0.78      0.75      0.77     30015\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.76      0.75     26816\n",
      "    positive       0.78      0.75      0.77     29893\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), min_df=3, max_df=0.4)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация\n",
    "\n",
    "Токенизировать -- значит, поделить текст на слова, или *токены*.\n",
    "\n",
    "Самый наивный способ токенизировать текст -- разделить с помощью `split`. Но `split` упускает очень много всего, например, банально не отделяет пунктуацию от слов. Кроме этого, есть ещё много менее тривиальных проблем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@first_timee', 'хоть', 'я', 'и', 'школота,', 'но', 'поверь,', 'у', 'нас', 'то', 'же', 'самое', ':D', 'общество', 'профилирующий', 'предмет', 'типа)']\n"
     ]
    }
   ],
   "source": [
    "print(df['text'].iloc[0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['003',\n",
       " '003r38hn6e',\n",
       " '004anna',\n",
       " '004hafarf4',\n",
       " '0060',\n",
       " '007',\n",
       " '0080',\n",
       " '008novublr',\n",
       " '009',\n",
       " '009_panda',\n",
       " '00_anita_00',\n",
       " '00_elenka',\n",
       " '00_kalashnikova',\n",
       " '00_katusha',\n",
       " '00c6a95bst',\n",
       " '00darya',\n",
       " '00dwpheuip',\n",
       " '00ennqulcp',\n",
       " '00gorbunova',\n",
       " '00lg6bsnb8']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.get_feature_names()[20:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем разбивать текст на слова с использованием регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "regex = re.compile(\"[А-Яа-я]+\")\n",
    "\n",
    "def words_only(text, regex=regex):\n",
    "    try:\n",
    "        return \" \".join(regex.findall(text))\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'хоть я и школота но поверь у нас то же самое общество профилирующий предмет типа'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_only(df['text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Но', 'не', 'каждый', 'хочет', 'что-то', 'исправлять', ':', '(']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять:('\n",
    "word_tokenize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', '9.5', 'or', '525,600', 'my', 'favorite', 'number', '?']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk вообще есть довольно много токенизаторов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BlanklineTokenizer',\n",
       " 'LineTokenizer',\n",
       " 'MWETokenizer',\n",
       " 'PunktSentenceTokenizer',\n",
       " 'RegexpTokenizer',\n",
       " 'ReppTokenizer',\n",
       " 'SExprTokenizer',\n",
       " 'SpaceTokenizer',\n",
       " 'StanfordSegmenter',\n",
       " 'SyllableTokenizer',\n",
       " 'TabTokenizer',\n",
       " 'TextTilingTokenizer',\n",
       " 'ToktokTokenizer',\n",
       " 'TreebankWordTokenizer',\n",
       " 'TweetTokenizer',\n",
       " 'WhitespaceTokenizer']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import tokenize\n",
    "dir(tokenize)[:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is 9.5 or 525,600 my favorite number ?\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import toktok\n",
    "\n",
    "toktok = toktok.ToktokTokenizer()\n",
    "text = u'Is 9.5 or 525,600 my favorite number?'\n",
    "print (toktok.tokenize(text, return_str=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Они умеют выдавать индексы начала и конца каждого токена:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2), (3, 5), (6, 12), (13, 18), (19, 25), (26, 38)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh_tok = tokenize.WhitespaceTokenizer()\n",
    "list(wh_tok.span_tokenize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(если вам было интересно, зачем вообще включать в модуль токенизатор, который работает как `.split()` :))\n",
    "\n",
    "Некторые токенизаторы ведут себя специфично:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\", 'stop', 'me']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.TreebankWordTokenizer().tokenize(\"don't stop me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых задач это может быть полезно.\n",
    "\n",
    "А некоторые -- вообще не для текста на естественном языке (не очень понятно, зачем это в nltk :)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(a (b c))', 'd', 'e', '(f)']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize.SExprTokenizer().tokenize(\"(a (b c)) d e (f)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самые частотные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2859146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69267),\n",
       " ('и', 54916),\n",
       " ('в', 52853),\n",
       " ('я', 52506),\n",
       " ('RT', 38070),\n",
       " ('на', 35715),\n",
       " ('http', 32992),\n",
       " ('что', 31472),\n",
       " ('...', 28773),\n",
       " ('с', 27177),\n",
       " ('а', 26592),\n",
       " ('меня', 20591),\n",
       " ('у', 18861),\n",
       " ('как', 18141),\n",
       " ('так', 16739),\n",
       " ('D', 16552),\n",
       " ('это', 16436),\n",
       " ('мне', 16247),\n",
       " ('все', 14695),\n",
       " ('ты', 13358)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "\n",
    "# freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "freq_dict.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Ципфа\n",
    "Эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В любом достаточно большом тексте ранг слова обратно пропорционален его частоте: $f = \\frac{a}{r}$\n",
    "\n",
    "$f$ – частота слова, $r$  – ранг слова, $a$  – параметр, для славянских языков – около 0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "freqs = list(freq_dict.values())\n",
    "freqs = sorted(freqs, reverse = True)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(freqs[:300], range(300))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Закон Хипса\n",
    "\n",
    "С увеличением длины текста (количества токенов), количество слов увеличивается в соответствии с законом: $|V| = K*N^b$\n",
    "\n",
    "\n",
    "$N$  –  число токенов, $|V|$  – количество слов в словаре, $K, b$  –  параметры, обычно $K \\in [10,100], b \\in [0.4, 0.6]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226834/226834 [17:31<00:00, 215.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cnt = Counter()\n",
    "n_words = []\n",
    "n_tokens = []\n",
    "tokens = []\n",
    "for index, row in tqdm(df.iterrows(), total = len(df)):\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    cnt.update([token for token in tokens if token not in punctuation])\n",
    "    n_words.append(len(cnt))\n",
    "    n_tokens.append(sum(cnt.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAD4CAYAAAAzZOvCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deXxU9b3/8dcHQtj3zUDYwQVQtrAo7nUBeitqXdAqiLaorba97bVq26tWbX+2t9orV4uiooBVxBVcKOKCVgQkAWRHAgQIYQ/7muXz+2O+tFNMQkJCJpm8n4/HPObMZ77nfD/fTDKfnDPfOcfcHRERkfJULdYJiIhI1aPiIyIi5U7FR0REyp2Kj4iIlDsVHxERKXcJsU6grDVr1szbt28f6zRERCqVtLS07e7evLz6i7vi0759e1JTU2OdhohIpWJm68qzPx12ExGRcqfiIyIi5U7FR0REyp2Kj4iIlDsVHxERKXcqPiIiUu5UfEREpNyp+IiIVHLrduznkfeWsevAkVinUmxx9yVTEZGqwN2ZvXoH42Zl8PGKLSRUM87u2JRLuraMdWrFouIjIlKJHMrJ450FG3npywxWbN5L07qJ3H1RZ24a0I4WDWrFOr1iO27xMbNawOdAzdD+DXd/0MxeAi4Adoemt7j7QjMz4ElgCHAgxOeHbY0AfhvaP+ru40O8D/ASUBv4APiZu7uZNQFeA9oDGcB17r6zlGMWEal0Nu8+xMQ5Gbwydz07D+RwRlID/nTNWVzRoxW1alSPdXolVpw9n8PAxe6+z8xqAF+Y2bTw3D3u/sYx7QcDXcKtPzAG6B8KyYNACuBAmplNDcVkDDAKmEOk+AwCpgH3AR+7+2Nmdl94fO+JD1dEpHJZsH4nL87K4IPFm8hz59IzWjJyYAcGdGxC5H/9yum4xcfdHdgXHtYINy9ilaHAhLDeHDNrZGZJwIXADHfPBjCzGcAgM5sJNHD32SE+AbiSSPEZGtYDGA/MRMVHROJcTl4+05Zs5sVZa1mwfhf1ayYw4pz2jDi7PW2b1ol1emWiWJ/5mFl1IA3oDDzt7nPN7E7g92b2APAxcJ+7HwZaAxuiVs8MsaLimQXEAVq6+yYAd99kZi1KOD4RkUpj5/4jvPLVeibOXsfmPYfo0Kwuv7uiG9/vk0y9mvH1EX2xRuPueUBPM2sEvG1m3YH7gc1AIjCWyB7Jw0BB+4F+AvFiM7NRRA7b0bZt25KsKiISc0uzdjPuiwzeX5zFoZx8zuvSjD9c3Z0LT21BtWqV99BaUUpUSt19VzhMNsjd/xzCh83sReC/wuNMoE3UaslAVohfeEx8ZognF9AeYIuZJYW9niRgayF5jSVSAElJSSlR4RIRiYW8fOfj5VsYN2stc9ZkUyexOlf3TuaWc9pzasv6sU7vpCvObLfmQE4oPLWBS4A/RhUFI/IZzZKwylTgLjObRGTCwe7QbjrwBzNrHNpdBtzv7tlmttfMBgBzgeHA/0VtawTwWLifUhaDFhGJlUM5ebw1fyPPfr6adTsO0KphLe4ffDrD+ralYZ0asU6v3BRnzycJGB8+96kGTHb398zsk1CYDFgI3BHaf0BkmnU6kanWIwFCkXkEmBfaPXx08gFwJ/+aaj0t3CBSdCab2W3AeuDaEx2oiEgs7dx/hJfnrGP87HVs33eYHskN+a8bejG4+ykkVK96J5uxyKS0+JGSkuK6jLaIVBRrt+/nhS/W8EZaJody8rnwtOb86LyOnNOpaYWaKm1mae6eUl79xdf0CRGRCsDdSVu3k7Gfr2HG8i3UqFaNq3q15ofndaBLFfg8pzhUfEREykhevvPR8i0889lqFqzfRaM6Nbjros7cfHY7WtSvPKe+KQ8qPiIipXTwSB5vLcjkxVkZpG/dR5smtXl4aDeu6ZNMnUS9zRZEPxURkRO0efchXvxyLa/OXc+eQ7l0a9WA0Tf0YkgVnURQEio+IiIltHDDLsZ/mcF7i7LIy3cGdT+FW87pQN/2jSvUJIKKTMVHRKQY3J3PvtnGmJmrmbs2m3o1E/hB/3bcdm4H2jSJj/OtlScVHxGRIhzKyWPKwo08/4+1rNq6j1Ma1OK33z2DYf3axt351sqTfnIiIgXYsucQE2ev45Wv1pO9/whnJDXgz9f24IoerUhM0Oc5paXiIyISZeGGXbw4ay3vL4pcP+c7p7fk1oHtObuCfSm0slPxEZEq79jr59SrmcDws9sz4px2tGtaN9bpxSUVHxGpsrL3H+HVqOvntG9ahwe/15Vr+iRTv1bVOclnLKj4iEiVs2LzHl6alcHbCzZyODefczs34/dXdeei0+L3+jkVjYqPiFQJefnOJyu28uKstXy5ege1alTj6t7JjBxYNa6fU9Go+IhIXNt7KIfJqZmM/zKD9dkHSGpYi3sHnc6wvm1oXDcx1ulVWSo+IhKXMrbv56UvM3g9dQP7j+TRp11jfjXoNC7vdgo1dOqbmFPxEZG44e7MSt/Bi7PW8snKrSRUM/7jrFaMHNies5IbxTo9iaLiIyKV3sEjeby9YCMvfbmWb7bso1m9RO6+uAs39W9Liwa6lEFFpOIjIpVW1q6DTJyzjle/Ws+uAzl0DWch+I+zkqhVo3qs05MiqPiISKXi7sxfv5NxszL4+5LNuDuXdT2FkQPb069DE52FoJI4bvExs1rA50DN0P4Nd3/QzDoAk4AmwHzgZnc/YmY1gQlAH2AHcL27Z4Rt3Q/cBuQBP3X36SE+CHgSqA487+6PhXiBfZTR2EWkEjmSm8/7i7N4cVYGizJ306BWAred24GbB7TTWaUroeLs+RwGLnb3fWZWA/jCzKYBvwD+4u6TzOwZIkVlTLjf6e6dzWwY8EfgejPrCgwDugGtgI/M7NTQx9PApUAmMM/Mprr7srBuQX2ISBWxfd9h/jZnPS/PXce2vYfp1Lwuj1zZnat7taauzipdaR33lXN3B/aFhzXCzYGLgRtDfDzwEJHCMDQsA7wBPGWR/eChwCR3PwysNbN0oF9ol+7uawDMbBIw1MyWF9GHiMS5o2cheGvBRo7k5nP+qc35n2vac36X5joLQRwo1r8NZlYdSAM6E9lLWQ3scvfc0CQTaB2WWwMbANw918x2A01DfE7UZqPX2XBMvH9Yp7A+js1vFDAKoG3btsUZkohUQHn5zkfLtzD+y4x/noXg+71b88PzOtKpeb1YpydlqFjFx93zgJ5m1gh4GzijoGbhvqB/SbyIeEHf9iqqfUH5jQXGAqSkpBTYRkQqrv2Hc5mcuoEXvlhL5s6DtNJZCOJeiQ6YuvsuM5sJDAAamVlC2DNJBrJCs0ygDZBpZglAQyA7Kn5U9DoFxbcX0YeIxIFtew8zYXYGE2avY/fBHFLaNeY3Q87g0q4tSdBZCOJacWa7NQdyQuGpDVxCZCLAp8A1RGajjQCmhFWmhsezw/OfuLub2VTgFTN7gsiEgy7AV0T2cLqEmW0biUxKuDGsU1gfIlKJrd62j+c+X8Nb8zeSk5/PpWe05PYLOtGnXeNYpyblpDh7PknA+PC5TzVgsru/Z2bLgElm9iiwAHghtH8BmBgmFGQTKSa4+1IzmwwsA3KBn4TDeZjZXcB0IlOtx7n70rCtewvpQ0QqodSMbJ75bDUfr9hKjerVuDYlmVvP7aDPc6ogi0xmix8pKSmempoa6zREJMjPd2Z+s5VnZq7hq4xsmtRN5Kb+bRl+Tnua1asZ6/QkMLM0d08pr/40SV5ETorcvHzeW7SJpz5NJ33rPlo1rMVvv3sGP+jfjtqJOvVNVafiIyJl6uCRPCanbuC5f6whc+dBTm1Zj/+9vidDzkwiMUGTCCRCxUdEysSOfYcZ/2UGE+asY9eBHHq3bcSD3+vGd07Xpanl21R8RKRUNmQf4Ll/rGFy6gYO5+ZzWdeW/PC8jvRt3yTWqUkFpuIjIidkWdYenvlsNe8v3kQ1g6t7JTPqAp2JQIpHxUdEis3dmbMmMl36s2+2UTexOred24FbB3bglIa6aJsUn4qPiBxXfr7z4bLNjPlsDV9v2EWzeoncc/lp3DSgHQ1r14h1elIJqfiISKEO5+bx9vyNjP18DWu276dd0zo8emV3rumTrCuFSqmo+IjIt+w9lMMrc9fzwhdr2br3MN1bN+CpG3sxuHsS1TVzTcqAio+I/NPWvYd4cVYGL89Zx95DuQzs3JQnruvJwM5NdXlqKVMqPiJCxvb9PPv5Gt6cn0lOXj5DuidxxwWdODO5YaxTkzil4iNShS3O3M0zn63mgyWbqFG9Gt/vncyo8zvSoVndWKcmcU7FR6SKcXe+SN/OM5+tZlb6DurXTOCOCzoxcmB7WtTXdGkpHyo+IlVEbl4+05Zs5tnPV7Nk4x5a1K/J/YNP58b+balfS9OlpXyp+IjEuUM5ebyelslzn69hffYBOjary2NXn8lVvVtTM0HTpSU2VHxE4tTuAzm8PHcdL85ay/Z9R+jRphG/HnI6l3Y9RdOlJeZUfETizObdh3hx1lpenrOO/UfyOP/U5txxQUfO7qjp0lJxqPiIxInMnQcYM3M1k1M3kJfvfPesVtxxQUe6tdJ0aal4jlt8zKwNMAE4BcgHxrr7k2b2EPAjYFto+mt3/yCscz9wG5AH/NTdp4f4IOBJoDrwvLs/FuIdgElAE2A+cLO7HzGzmqHvPsAO4Hp3zyiDcYvEjfSt+xgzczVTFm7EDK5LacPt53eibdM6sU5NpFDF2fPJBX7p7vPNrD6QZmYzwnN/cfc/Rzc2s67AMKAb0Ar4yMxODU8/DVwKZALzzGyquy8D/hi2NcnMniFSuMaE+53u3tnMhoV215dmwCLxYsnG3Tz9aTp/X7qZmgnVGH52e350fgeSGtaOdWoix3Xc4uPum4BNYXmvmS0HWhexylBgkrsfBtaaWTrQLzyX7u5rAMxsEjA0bO9i4MbQZjzwEJHiMzQsA7wBPGVm5u5e7BGKxJlVW/by5w9XMn3pFurXSuDHF3bi1oEdaFqvZqxTEym2En3mY2btgV7AXGAgcJeZDQdSiewd7SRSmOZErZbJv4rVhmPi/YGmwC53zy2gfeuj67h7rpntDu23H5PXKGAUQNu2bUsyJJFKY+32/Tz50TdM+TqLuokJ/PySLtx6bgca6Ds6UgkVu/iYWT3gTeDn7r7HzMYAjwAe7h8HbgUKmk7jQLVC4oW15zjP/SvgPhYYC5CSkqK9IokrG7IP8NQn6bwxP5Ma1Y1R53fkjvM70bhuYqxTEzlhxSo+ZlaDSOH5m7u/BeDuW6Kefw54LzzMBNpErZ4MZIXlguLbgUZmlhD2fqLbH91WppklAA2B7GKPTqQSy9x5gP/7OFJ0qpsx/Ox23HlhJ50CR+JCcWa7GfACsNzdn4iKJ4XPgwCuApaE5anAK2b2BJEJB12Ar4jsxXQJM9s2EpmUcKO7u5l9ClxDZMbbCGBK1LZGALPD85/o8x6Jd1m7DjJm5momzVuPYdw8oB23X9BREwkkrhRnz2cgcDOw2MwWhtivgRvMrCeRw2AZwO0A7r7UzCYDy4jMlPuJu+cBmNldwHQiU63HufvSsL17gUlm9iiwgEixI9xPDJMWsokULJG4tPtADk99uooJs9eRl+9cm9KGuy/uTKtGKjoSfyzediRSUlI8NTU11mmIFFt+vvPm/Ewem7aCnQeOcGWv1vzi0lNJbqzv6Uj5MbM0d08pr/50hgORGFqatZsHpiwlbd1O+rRrzISh/XRGAqkSVHxEYmDPoRye+PAbJszOoHGdRP7nmrP4fu9kqumEn1JFqPiIlCN35+0FG/nDByvI3n+Ymwa045eXnkbDOvqujlQtKj4i5WTF5j088M5SvsrIpmebRrw0si/dW+sQm1RNKj4iJ9neQzn870ereOnLDBrUSuCP3z+Ta/u00SE2qdJUfEROEndn6tdZPPr+crbvO8wN/dryq8tPo1EdnZlARMVH5CRYtWUv/z1lCXPWZHNWckOeH55CjzaNYp2WSIWh4iNShvYdzmX0x6sY98Va6tZM4PdXdWdY37a6bLXIMVR8RMqAu/P+4k08+t5yNu85xLC+bfjVoNNpopN/ihRIxUeklNK37uOhqUv5In073Vo14K839aZ328axTkukQlPxETlBB47k8n+fpPP8P9ZQu0Z1HhnajRv7t9MhNpFiUPERKSF35+9LNvPIe8vI2n2Ia/okc9/g02mmK4mKFJuKj0gJrN2+nwenLuXzb7ZxRlIDRt/Qi5T2TWKdlkilo+IjUgwHj+Tx9KfpjP18DTUTqvHg97py84B2JFQv6AK9InI8Kj4iRXB3Zizbwu/eXcbGXQe5uldr7htyuq4mKlJKKj4ihdiQfYDfvbuUj5Zv5bSW9Xlt1AD6d2wa67RE4oKKj8gxcvPymThnHX/6+0rM4NdDTmfkwA7U0CE2kTKj4iMSJW3dTh6YsoSlWXu44NTm/OHqM2mty1iLlDkVHxFg94EcHn1/Ga+nZdKyQU3++oPeDO5+Cmb6zo7IyXDc4whm1sbMPjWz5Wa21Mx+FuJNzGyGma0K941D3MxstJmlm9kiM+sdta0Rof0qMxsRFe9jZovDOqMt/MUX1odIWXF3pizcyEWPz+StBRu544JOfPLLCxlyZpIKj8hJVJyD2LnAL939DGAA8BMz6wrcB3zs7l2Aj8NjgMFAl3AbBYyBSCEBHgT6A/2AB6OKyZjQ9uh6g0K8sD5ESi1r10Fun5jGzyYtpG2TOrx717ncN/h06tbUAQGRk+24f2XuvgnYFJb3mtlyoDUwFLgwNBsPzATuDfEJ7u7AHDNrZGZJoe0Md88GMLMZwCAzmwk0cPfZIT4BuBKYVkQfIicsNy+fCbPX8fiHK8lz5/7Bp/PD8zrqtDgi5ahE/+KZWXugFzAXaBkKE+6+ycxahGatgQ1Rq2WGWFHxzALiFNHHsXmNIrLnRNu2bUsyJKli0rfu5ZevL+LrDbu44NTmPHpld9o0qRPrtESqnGIXHzOrB7wJ/Nzd9xRxPLygJ/wE4sXm7mOBsQApKSklWleqhpy8fMZ9sZbHZ3xD3cTqPDmsJ1f0aKXPdURipFjFx8xqECk8f3P3t0J4i5klhT2SJGBriGcCbaJWTwayQvzCY+IzQzy5gPZF9SFSbIszd3Pvm4tYtmkPl3Ztye+v6q4zFIjEWHFmuxnwArDc3Z+IemoqcHTG2ghgSlR8eJj1NgDYHQ6dTQcuM7PGYaLBZcD08NxeMxsQ+hp+zLYK6kPkuA7l5PH/pi1n6NNfsH3fYZ65qQ9jb+6jwiNSARRnz2cgcDOw2MwWhtivgceAyWZ2G7AeuDY89wEwBEgHDgAjAdw928weAeaFdg8fnXwA3Am8BNQmMtFgWogX1odIkeZlZHPP61+TseMAw/q24f4hZ9Cwdo1YpyUigUUmpcWPlJQUT01NjXUaEiMHjuTyP9NX8tKXGSQ3rs0frz6Lczo3i3VaIhWemaW5e0p59acvNEjcmLtmB796cxHrdhzg5gHt9J0dkQpMf5lS6R04ksuf/h7Z22nbpA6v/mgAZ3fS2adFKjIVH6nU5q/fyS9eW8i67AOMHNieey4/jTqJ+rUWqej0VyqV0uHcPJ6Y8Q3Pfb6GpIa1efVHAxiga+2IVBoqPlLpLM3azS9e+5qVW/YyrG8bfv3dM2hQSzPZRCoTFR+pNHLz8hkzczVPfryKJnUTefGWvlx0eoFnXBKRCk7FRyqF1dv28YvJX/P1hl1c0aMVDw/tRqM6ibFOS0ROkIqPVGj5+c742Rk8Nm0FtROr89SNvfiPs1rFOi0RKSUVH6mwsnYd5J43vmZW+g4uPr0Fj119Ji0a6NQ4IvFAxUcqpCkLN/Lbd5aQl+/84aozuaFfG52BWiSOqPhIhbL7QA7/PWUJU7/OonfbRvzl+p60a1o31mmJSBlT8ZEK4x+rtnHP64vYtu8wv7z0VO68sBMJ1YtzpXcRqWxUfCTmcvLyefKjVTw9M52Ozery3PCBnJncMNZpichJpOIjMbUh+wA/nbSABet3cW2fZB4e2p3aidVjnZaInGQqPhIz7y3K4v43FwMw+oZeXNFDU6hFqgoVHyl3B47k8vC7y5g0bwO92jZi9LBetGlSJ9ZpiUg5UvGRcrUsaw93vzqfNdv385OLOvHzS06lhiYViFQ5Kj5SLtyd8V9m8IcPVtCoTg1evq0/A3WFUZEq67j/cprZODPbamZLomIPmdlGM1sYbkOinrvfzNLNbKWZXR4VHxRi6WZ2X1S8g5nNNbNVZvaamSWGeM3wOD08376sBi3lK3v/EX40IZWH3l3GuV2aMe1n56nwiFRxxTne8RIwqID4X9y9Z7h9AGBmXYFhQLewzl/NrLqZVQeeBgYDXYEbQluAP4ZtdQF2AreF+G3ATnfvDPwltJNK5svV2xn85Od8/s12HvxeV14YkULTejVjnZaIxNhxi4+7fw5kF3N7Q4FJ7n7Y3dcC6UC/cEt39zXufgSYBAy1yPlSLgbeCOuPB66M2tb4sPwG8B3T+VUqjZy8fP48fSU/eH4udWsm8PZPzmHkwA46RY6IAMXb8ynMXWa2KByWaxxirYENUW0yQ6yweFNgl7vnHhP/t22F53eH9t9iZqPMLNXMUrdt21aKIUlZ2JB9gOufnc1Tn6ZzbZ9k3rv7XLq10pdGReRfTrT4jAE6AT2BTcDjIV7Qv7V+AvGitvXtoPtYd09x95TmzZsXlbecZB8s3sSQ0f9g1ZZ9jL6hF3+6pgd1EjWvRUT+3Qm9K7j7lqPLZvYc8F54mAm0iWqaDGSF5YLi24FGZpYQ9m6i2x/dVqaZJQANKf7hPylnh3LyePi9Zbwydz092zTi/27Qd3dEpHAntOdjZklRD68Cjs6EmwoMCzPVOgBdgK+AeUCXMLMtkcikhKnu7sCnwDVh/RHAlKhtjQjL1wCfhPZSwXyzZS9XPj2LV+au5/YLOjL59rNVeESkSMfd8zGzV4ELgWZmlgk8CFxoZj2JHAbLAG4HcPelZjYZWAbkAj9x97ywnbuA6UB1YJy7Lw1d3AtMMrNHgQXACyH+AjDRzNKJ7PEMK/VopUy5O69+tYHfvbuU+rUSeHFkXy46rUWs0xKRSsDibWciJSXFU1NTY51G3NtzKIf731rM+4s2cV6XZjxxXU+a19cUapHKyszS3D2lvPrTJ8FSYss37eHOl9PYsPMgvxp0Gnec34lq1TSFWkSKT8VHis3dmZy6gQemLKVRnRpMGjWAvu2bxDotEamEVHykWPYdzuWBd5bw1oKNnNOpKU8O66XDbCJywlR85LiWZu3m7lcXsHb7fn5+SRfuvrgL1XWYTURKQcVHivR66gZ++84SGtauwSs/HMDZnQo8yYSISImo+EiBjuTm88h7y5g4Zx3ndGrK6Bt60UwnBBWRMqLiI9+ydc8hRk1MY+GGXYw6vyO/uvw0EnTBNxEpQyo+8m/S1mXz47/NZ++hXJ6+sTffPSvp+CuJiJSQio8AkWnUE+es4+F3l9GqUW1evKMfXVs1iHVaIhKnVHyEQzl5/ObtJbw5P5OLT2/BX67vScPaNWKdlojEMRWfKi5z5wHueDmNJRv38LPvdOFn3+misxWIyEmn4lOFpa3LZtSENI7k5fP88BQu6doy1imJSBWh4lNFTVm4kV+9sYhWjWrz3PAUOreoF+uURKQKUfGpYvLznT9/uJK/zlxNvw5NeOamPjSpmxjrtESkilHxqUJ2H8zhF68t5OMVW7mhXxt+d0V3EhP0/R0RKX8qPlXE0csgZO48yO+u6Mbws9thpokFIhIbKj5VwFvzM/n124tpUKsGr+oyCCJSAaj4xLHDuXk8/O4y/jZ3PQM6NmH0Db1oUb9WrNMSEVHxiVdZuw5y58tpfJ25m9sv6Mg9l+n8bCJScRz33cjMxpnZVjNbEhVrYmYzzGxVuG8c4mZmo80s3cwWmVnvqHVGhParzGxEVLyPmS0O64y28EFEYX3I8c3LyOa7o/9B+tZ9PHNTH+4ffIYKj4hUKMV5R3oJGHRM7D7gY3fvAnwcHgMMBrqE2yhgDEQKCfAg0B/oBzwYVUzGhLZH1xt0nD6kCFMWbuTG5+bQqE4i7959LoO6nxLrlEREvuW4xcfdPweyjwkPBcaH5fHAlVHxCR4xB2hkZknA5cAMd892953ADGBQeK6Bu892dwcmHLOtgvqQArg7z362mp9NWkjvto1558cD6dhcXxwVkYrpRD/zaenumwDcfZOZtQjx1sCGqHaZIVZUPLOAeFF9fIuZjSKy90Tbtm1PcEiV15HcfH7z9mJeT8vku2cm8fh1PahVo3qs0xIRKVRZTzgo6IsjfgLxEnH3scBYgJSUlBKvX5ntPpjDHRPTmL1mBz/9Thf+85Iu+v6OiFR4J/op9JZwyIxwvzXEM4E2Ue2SgazjxJMLiBfVhwSbdh/kumdmk7oumyeu68EvLj1VhUdEKoUTLT5TgaMz1kYAU6Liw8OstwHA7nDobDpwmZk1DhMNLgOmh+f2mtmAMMtt+DHbKqgPAb7Zsper//olG3cd5KWR/bi6d/LxVxIRqSCOe9jNzF4FLgSamVkmkVlrjwGTzew2YD1wbWj+ATAESAcOACMB3D3bzB4B5oV2D7v70UkMdxKZUVcbmBZuFNFHlTcvI5vbXppHzRrVee32AXRr1TDWKYmIlIhFJpnFj5SUFE9NTY11GifN35ds5qeTFpDcuDbjR/ajTZM6sU5JROKAmaW5e0p59aczHFQiE+es44EpS+iR3Ihxt/TVpRBEpNJS8akE3J3HP/yGpz5N5zunt+CpG3tTO1FTqUWk8lLxqeBy8/L59duLmZyayfUpbfj9Vd11qhwRqfRUfCqwg0fyuPvV+Xy0fCs/vbgz/6mp1CISJ1R8Kqitew/xw/GpLN64m0eGduPms9vHOiURkTKj4lMBrdy8l1te/IpdB3IYe3MKl3ZtGeuURETKlIpPBTNnzQ5+NCGV2jWq88adZ+s7PCISl1R8KpBPV2zljpfTaNOkDi+N7EtyY32HR0Tik4pPBfH+ok38/LUFnHZKfSbc2l/f4RGRuKbiUwG8nrqBe99cRO+2jRk3si8NatWIdUoiIieVik+Mjf8yg1vu3iwAAAtbSURBVAenLuW8Ls149uY+1EnUSyIi8U/vdDH0zGereWzaCi7t2pKnbuxFzQSdtUBEqgYVnxh5/h9reGzaCr7XoxVPXNeDGjprgYhUISo+MfDirLU8+v5yvntmEn+5rodOlyMiVY7e9crZhNkZ/O7dZQzqdgr/O6ynCo+IVEl65ytHL89ZxwNTlnJp15aMvqGXDrWJSJWld79yMumr9fz2nSVcckYLnr6xN4kJ+tGLSNWld8ByMDl1A/e/vZiLTmvO0z9Q4RERKdW7oJllmNliM1toZqkh1sTMZpjZqnDfOMTNzEabWbqZLTKz3lHbGRHarzKzEVHxPmH76WHdSnc9gTfTMrn3zUWc27kZY27qo+nUIiKUzZ7PRe7eM+ra3/cBH7t7F+Dj8BhgMNAl3EYBYyBSrIAHgf5AP+DBowUrtBkVtd6gMsi33LyzYCP/9cbXnNOpKc8NT6FWDRUeERE4OYfdhgLjw/J44Mqo+ASPmAM0MrMk4HJghrtnu/tOYAYwKDzXwN1nu7sDE6K2VeFN/TqLX0xeSP8OTXh+eF8VHhGRKKUtPg58aGZpZjYqxFq6+yaAcN8ixFsDG6LWzQyxouKZBcS/xcxGmVmqmaVu27atlEMqvU9WbOE/X1tISvsmjLulL7UTVXhERKKV9kumA909y8xaADPMbEURbQv6vMZPIP7toPtYYCxASkpKgW3Ky+zVO7jj5fmckVSfF0ak6FxtIiIFKNWej7tnhfutwNtEPrPZEg6ZEe63huaZQJuo1ZOBrOPEkwuIV1jLN+1h1IRU2jWpw8Rb+1NfZ6cWESnQCRcfM6trZvWPLgOXAUuAqcDRGWsjgClheSowPMx6GwDsDoflpgOXmVnjMNHgMmB6eG6vmQ0Is9yGR22rwtm69xC3vTSPujUTGH9rPxrrejwiIoUqzTGhlsDbYfZzAvCKu//dzOYBk83sNmA9cG1o/wEwBEgHDgAjAdw928weAeaFdg+7e3ZYvhN4CagNTAu3CudQTh6jJqSx80AOr99xNq0a1Y51SiIiFZpFJpLFj5SUFE9NTS23/tyd/3xtIe8szOKZm3ozqHtSufUtIlJWzCwt6iszJ52+al9Koz9O552FWdxz+WkqPCIixaTiUwrvLNjIXz76hqt7t+bHF3aKdToiIpWGis8JWpy5m3vfXES/Dk344/fPohKe+UdEJGZUfE7Axl0HGTUxlWb1avLXH/TWpRFEREpI75oldOBILj8cn8q+Q7k8NzyFZvVqxjolEZFKR1+/LwF351dvLGLF5j2Mu6UvXVs1iHVKIiKVkvZ8SuCFL9by3qJN3HP5aVx0WovjryAiIgVS8SmmeRnZ/L9pK7i8W0vuvEAz20RESkPFpxh27DvM3a8sILlxbf58bQ/NbBMRKSV95nMc7s69by4ie/8R3vrxOTpZqIhIGdCez3G8+tUGPlq+lXsHn0731g1jnY6ISFxQ8SnCuh37efT9ZQzs3JSR57SPdToiInFDxacQ+fnOPW8soroZ/3NND6pV0+c8IiJlRcWnEBPnrOOrtdn89/e66hIJIiJlTMWnANv3HebxD1dybudmXNsn+fgriIhIiaj4FOBPf1/BwZw8Hrqiq6ZVi4icBCo+x1iycTevp2Vyyznt6dyifqzTERGJSyo+x/jDB8tpUieRu7/TJdapiIjELRWfKLNX7+DL1Tv4yUWdaaAvk4qInDQVvviY2SAzW2lm6WZ238nsa+znq2lWryY39m97MrsREanyKnTxMbPqwNPAYKArcIOZdT0ZfWVs38+nK7dx04C21KpR/WR0ISIiQYUuPkA/IN3d17j7EWASMPRkdPTu11kAXN+3zcnYvIiIRKnoxac1sCHqcWaI/RszG2VmqWaWum3bthPqqGWDWlyXkkxSQ32hVETkZKvoxaegL9n4twLuY909xd1TmjdvfkIdXde3DX+6pscJrSsiIiVT0YtPJhB9HCwZyIpRLiIiUkYqevGZB3Qxsw5mlggMA6bGOCcRESmlCn0xOXfPNbO7gOlAdWCcuy+NcVoiIlJKFbr4ALj7B8AHsc5DRETKTkU/7CYiInFIxUdERMqdio+IiJQ7FR8RESl35v6t72xWama2DVh3gqs3A7aXYToVQTyOCeJzXBpT5RCPYwI4zd3L7SJmFX62W0m5+4md4gAws1R3TynLfGItHscE8TkujalyiMcxQWRc5dmfDruJiEi5U/EREZFyp+Lz78bGOoGTIB7HBPE5Lo2pcojHMUE5jyvuJhyIiEjFpz0fEREpdyo+IiJS7lR8AjMbZGYrzSzdzO6LdT4AZpZhZovNbOHRaZBm1sTMZpjZqnDfOMTNzEaH/BeZWe+o7YwI7VeZ2YioeJ+w/fSwrhXVRynGMc7MtprZkqhYzMZRVB+lHNNDZrYxvF4LzWxI1HP3h/5WmtnlUfECf+/CZUTmhtxfC5cUwcxqhsfp4fn2x+ujBGNqY2afmtlyM1tqZj8L8Ur7WhUxpkr7WplZLTP7ysy+DmP6XVnnUZZjLZS7V/kbkcs1rAY6AonA10DXCpBXBtDsmNifgPvC8n3AH8PyEGAakau/DgDmhngTYE24bxyWG4fnvgLODutMAwYX1UcpxnE+0BtYUhHGUVgfZTCmh4D/KqBt1/A7VRPoEH7Xqhf1ewdMBoaF5WeAO8Pyj4FnwvIw4LWi+ijhmJKA3mG5PvBN2G6lfa2KGFOlfa3Cz6JeWK4BzA0/mzLJoyzHWuQ4SvOmEi+38McwPerx/cD9FSCvDL5dfFYCSWE5CVgZlp8Fbji2HXAD8GxU/NkQSwJWRMX/2a6wPko5lvb8+xt1zMZRWB9lMKaHKPgN7d9+n4hcn+rswn7viLy5bAcSjv39PLpuWE4I7aywPkr5mk0BLo2H16qAMcXFawXUAeYD/csqj7Ica1G567BbRGtgQ9TjzBCLNQc+NLM0MxsVYi3dfRNAuG8R4oWNoah4ZgHxovooS7Ecx8l8ve8Kh4fG2b8OV5Z0TE2BXe6eW0B+/1wnPL87tC/TMYXDJr2I/FcdF6/VMWOCSvxamVl1M1sIbAVmENlTKas8ynKshVLxibACYhVhDvpAd+8NDAZ+YmbnF9G2sDGUNB5r5TGOkzX2MUAnoCewCXj8OP2dyJhO+utpZvWAN4Gfu/ueopqWMJeYvVYFjKlSv1bunufuPYFkoB9wRhnmUZZjLZSKT0Qm0CbqcTKQFaNc/snds8L9VuBtIr9kW8wsCSDcbw3NCxtDUfHkAuIU0UdZiuU4Tsrr7e5bwptCPvAckdfrRMa0HWhkZgnHxP9tW+H5hkB2WY3JzGoQeZP+m7u/FcKV+rUqaEzx8FqFcewCZhL5zKes8ijLsRZKxSdiHtAlzORIJPKB2dRYJmRmdc2s/tFl4DJgSchrRGg2gsgxbEJ8eJgdNADYHQ5fTAcuM7PG4dDCZUSO024C9prZADMzYPgx2yqoj7IUy3EU1kepHH3zDK4i8nod7W9YmBHUAehC5IP3An/vPHLg/FPgmkJyPzqma4BPQvvC+ihJ/ga8ACx39yeinqq0r1VhY6rMr5WZNTezRmG5NnAJsLwM8yjLsRbuRD+4i7cbkVk13xA5dvqbCpBPRyKzTL4Glh7Nichx1I+BVeG+SYgb8HTIfzGQErWtW4H0cBsZFU8h8ke3GniKf53xosA+SjGWV4kc2sgh8h/SbbEcR1F9lHJME8P2FoU/xqSo9r8J/a0kzPAq6vcuvP5fhbG+DtQM8VrhcXp4vuPx+ijBmM4lcqhkEbAw3IZU5teqiDFV2tcKOAtYEHJfAjxQ1nmU5VgLu+n0OiIiUu502E1ERMqdio+IiJQ7FR8RESl3Kj4iIlLuVHxERKTcqfiIiEi5U/EREZFy9/8BKiNvGUM/BI8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_tokens, n_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/anyala/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (как написано выше)\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.76      0.78     29206\n",
      "    positive       0.76      0.80      0.78     27503\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось чууть лучше. Что ещё можно сделать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "У каждого слова есть лемма (нормальная форма):\n",
    "\n",
    "    кошке, кошку, кошкам, кошкой ⟹ кошка\n",
    "    бежал, бежит, бегу ⟹ бежать\n",
    "    белому, белым, белыми ⟹ белый\n",
    "\n",
    "\n",
    "**Лемматизация** – это приведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymystem3\n",
      "  Downloading https://files.pythonhosted.org/packages/00/8c/98b43c5822620458704e187a1666616c1e21a846ede8ffda493aabe11207/pymystem3-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from pymystem3) (2.22.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages (from requests->pymystem3) (1.24.2)\n",
      "Installing collected packages: pymystem3\n",
      "Successfully installed pymystem3-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ':(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ':(\\n'}]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте терепь использовать лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords_ru = set(stopwords.words('russian'))\n",
    "stopwords_ru.update([' ', '\\n'])\n",
    "\n",
    "def my_preproc(text, stopwords = stopwords_ru):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.74      0.76     29416\n",
      "    positive       0.73      0.77      0.75     27293\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый, с большим количеством функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((<DictionaryAnalyzer>, 'платили', 2368, 10),))]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь напишите аналогичную функцию для лемматизации с pymorphy2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что будет, если использовать её в качестве препроцессора? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'\n",
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'Действительно, на его лице не отражалось никаких чувств – ни проблеска сочувствия не было на нем, а ведь боль просто невыносима'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на он лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на нем, а ведь боль просто невыносимый\n"
     ]
    }
   ],
   "source": [
    "lemmas1 = [pymorphy2_analyzer.parse(word)[0].normal_form for word in sent1.split()]\n",
    "print(' '.join(lemmas1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "действительно, на его лицо не отражаться никакой чувство – ни проблеск сочувствие не быть на немой, а ведь боль просто невыносимый\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lemmas2 = mystem_analyzer.lemmatize(sent1)\n",
    "print(''.join(lemmas2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Стемминг\n",
    "\n",
    "Слова состоят из морфем: 𝑤𝑜𝑟𝑑=𝑠𝑡𝑒𝑚+𝑎𝑓𝑓𝑖𝑥𝑒𝑠. Стемминг позволяет отбросить аффиксы. Чаще всего используется алгоритм Портера.\n",
    "\n",
    "Алгоритм Портера состоит из 5 циклов команд, на каждом цикле – операция удаления / замены суффикса. Возможны вероятностные расширения алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "распределен\n",
      "пристав\n",
      "сдела\n",
      "словообразован\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import RussianStemmer\n",
    "\n",
    "stemmer = RussianStemmer()\n",
    "words = ['распределение', 'приставить', 'сделала', 'словообразование']\n",
    "for w in words:\n",
    "    stem = stemmer.stem(w)\n",
    "    print(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anyala/miniconda3/envs/mlenv/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     27946\n",
      "    positive       1.00      1.00      1.00     28763\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоило оставить пунктуацию -- и все метрики равны 1! Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициэнтами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как один из супер-значительных токенов справится с классификацией безо всякого машинного обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32916\n",
      "    positive       0.83      1.00      0.91     23793\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.91      0.92      0.91     56709\n",
      "weighted avg       0.93      0.91      0.91     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = \n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.99      1.00      1.00     27667\n",
      "   positive       1.00      0.99      1.00     29042\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1. Так или инчае, на символах классифицировать тоже можно: для некторых задач (например, для определения языка) фичи-символьные n-граммы оказываются очень значимыми.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готвых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сегментация предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Знаки \".\", \"?\", \"!\" не всегда однозначно определяют границы предложений.\n",
    "\n",
    "Бинарный классификатор для сегментации предложений: для каждой точки \".\" определить, является ли она концом предложения или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rusenttokenize\n",
      "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
      "Installing collected packages: rusenttokenize\n",
      "Successfully installed rusenttokenize-0.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install rusenttokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rusenttokenize import ru_sent_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Эта шоколадка за 400р.\n",
      "ничего из себя не представляла.\n",
      "В г.\n",
      "2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.\n",
      "\n",
      "3\n",
      "Эта шоколадка за 400р. ничего из себя не представляла.\n",
      "В г. 2019 Артём решил больше не ходить в этот магазин на берегу р.\n",
      "Москвы.\n"
     ]
    }
   ],
   "source": [
    "text = 'Эта шоколадка за 400р. ничего из себя не представляла. В г. 2019 Артём решил больше не ходить в этот магазин на берегу р. Москвы.'\n",
    "\n",
    "\n",
    "\n",
    "sents = sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')\n",
    "\n",
    "print()\n",
    "sents = ru_sent_tokenize(text)\n",
    "\n",
    "print(len(sents))\n",
    "print(*sents, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Регулярные выражения\n",
    "Вообще, часто бывает так, что для конкретного случая нужен особый способ токенизации, и надо самостоятельно написать регулярку. Или, например, перед работой с текстом, надо почистить его от своеобразного мусора: упоминаний пользователей, url и так далее.\n",
    "\n",
    "Навык полезный, давайте в нём тоже потренируемся."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Классы символов:*__\n",
    "\n",
    "__[A-Z]__ – символы верхнего регистра (латиница)\n",
    "\n",
    "__[a-z]__ – символы нижнего регистра (латиница)\n",
    "\n",
    "__[А-Я]__ – символы верхнего регистра (кириллица)\n",
    "\n",
    "__[а-я]__ – символы нижнего регистра (кириллица)\n",
    "\n",
    "__[0-9]__ или __\\d__ – цифра\n",
    "\n",
    "__[^0-9]__ или __\\D__ – любой символ, кроме цифры\n",
    "\n",
    "__.__ – любой символ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Служебные символы:*__\n",
    "\n",
    "__\\t__ – табуляция\n",
    "\n",
    "__\\s__ – любой пробельный символ\n",
    "\n",
    "__\\S__ – все символы, кроме пробельных\n",
    "\n",
    "__\\n__ – перенос строки\n",
    "\n",
    "__^__ – начало строки\n",
    "\n",
    "__$__ – конец строки\n",
    "\n",
    "__\\__ – экранирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__*Операторы:*__\n",
    "\n",
    "__?__ - предыдущий символ/группа может быть, а может не быть\n",
    "\n",
    "__+__ - предыдущий символ/группа может повторяться 1 и более раз\n",
    "\n",
    "__*__ - предыдущий символ/группа может повторяться 0 и более раз\n",
    "\n",
    "__{n,m}__ - предыдущий символ/группа может повторяться от от n до m включительно\n",
    "\n",
    "__{n,}__ - предыдущий символ/группа в скобках может повторяться n и более раз\n",
    "\n",
    "__{,m}__ - предыдущий символ/группа может повторяться до m раз\n",
    "\n",
    "__{n}__ - предыдущий символ/группа повторяется n раз\n",
    "\n",
    "Внутри групп не работают операторы __.__, __+__, __*__, их необходимо экранировать с помощью обратного слеша: \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### findall\n",
    "возвращает список всех найденных совпадений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abca']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('ab+c.', 'abcdefghijkabcabcxabc') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вопрос на внимательность: почему нет abcx?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список первых двух букв каждого слова в строке, состоящей из нескольких слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Кот сидит на столе'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split\n",
    "разделяет строку по заданному шаблону\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie', ' weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie') \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно указать максимальное количество разбиений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['itsy', ' bitsy', ' teenie, weenie']\n"
     ]
    }
   ],
   "source": [
    "result = re.split(',', 'itsy, bitsy, teenie, weenie', maxsplit = 2) \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: разбейте строку, состоящую из нескольких предложений, по точкам, но не более чем на 3 предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sub\n",
    "ищет шаблон в строке и заменяет все совпадения на указанную подстроку\n",
    "\n",
    "параметры: (pattern, repl, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbcbbc\n"
     ]
    }
   ],
   "source": [
    "result = re.sub('a', 'b', 'abcabc')\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая заменяет все цифры в строке на \"DIG\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: напишите регулярку, которая убирает url из строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compile\n",
    "компилирует регулярное выражение в отдельный объект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Слова', 'Да', 'больше', 'ещё', 'больше', 'слов', 'Что-то', 'ещё']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Пример: построение списка всех слов строки:\n",
    "prog = re.compile('[А-Яа-яё\\-]+')\n",
    "prog.findall(\"Слова? Да, больше, ещё больше слов! Что-то ещё.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: для выбранной строки постройте список слов, которые длиннее трех символов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание**: вернуть список доменов (@gmail.com) из списка адресов электронной почты:\n",
    "\n",
    "```\n",
    "abc.test@gmail.com, xyz@test.in, test.first@analyticsvidhya.com, first.test@rest.biz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если всё ещё осталось время: [регулярочный кроссворд ¯\\_(ツ)_/¯](https://mariolurig.com/crossword/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
